import React, { useCallback, useEffect, useState } from "react";

const RECORD_STATE_TYPE = {
  INTERVIEW_BEFORE: 0,
  QUESTION_BEFORE: 1,
  QUESTIONING: 2,
  ANSWER_BEFORE: 3,
  ANSWERING: 4,
  SAVING: 5,
};

const BUTTON_NAME = {
  [RECORD_STATE_TYPE.INTERVIEW_BEFORE]: "ë©´ì ‘ ì‹œì‘",
  [RECORD_STATE_TYPE.QUESTION_BEFORE]: "ì§ˆë¬¸ í•˜ê¸°",
  [RECORD_STATE_TYPE.QUESTIONING]: "ì§ˆë¬¸ ì¢…ë£Œ",
  [RECORD_STATE_TYPE.ANSWER_BEFORE]: "ë‹µë³€ í•˜ê¸°",
  [RECORD_STATE_TYPE.ANSWERING]: "ë‹µë³€ ì™„ë£Œ",
  [RECORD_STATE_TYPE.SAVING]: "ì €ì¥ ì¤‘...",
};

const SpeechRecognition =
  window.SpeechRecognition || window.webkitSpeechRecognition;

export default function VoiceToTextTestPage() {
  const [question, setQuestion] = useState([]);
  const [answer, setAnswer] = useState([]);
  const [recordBtnState, setRecordBtnState] = useState(RECORD_STATE_TYPE.INTERVIEW_BEFORE);

  const setNextRecordBtnState = useCallback(() => {
    switch (recordBtnState) {
      case RECORD_STATE_TYPE.INTERVIEW_BEFORE:
        setRecordBtnState(RECORD_STATE_TYPE.QUESTION_BEFORE);
        break;
      case RECORD_STATE_TYPE.QUESTION_BEFORE:
        setRecordBtnState(RECORD_STATE_TYPE.QUESTIONING);
        break;
      case RECORD_STATE_TYPE.QUESTIONING:
        setRecordBtnState(RECORD_STATE_TYPE.ANSWER_BEFORE);
        break;
      case RECORD_STATE_TYPE.ANSWER_BEFORE:
        setRecordBtnState(RECORD_STATE_TYPE.ANSWERING);
        break;
      case RECORD_STATE_TYPE.ANSWERING:
        setRecordBtnState(RECORD_STATE_TYPE.SAVING);
        break;
      // case RECORD_STATE_TYPE.SAVING:
      //   setRecordBtnState(RECORD_STATE_TYPE.QUESTION_BEFORE);
      //   break;
      default:
        setRecordBtnState(RECORD_STATE_TYPE.QUESTION_BEFORE);
        break;
    }
  }, [recordBtnState]);

  function handleClickRecord() {
    setNextRecordBtnState();
  }

  const handleKeyPress = useCallback(
    (event) => {
      if (event.key === " " || event.key === "Spacebar") {
        setNextRecordBtnState();
      }
    },
    [setNextRecordBtnState]
  );

  useEffect(() => {
    document.addEventListener("keypress", handleKeyPress);

    return () => {
      document.removeEventListener("keypress", handleKeyPress);
    };
  }, [handleKeyPress]);

  // Speech Recognition ê´€ë ¨ Side Effect
  useEffect(() => {
    if (!SpeechRecognition) {
      console.error("Speech recognition not supported ğŸ˜¢ (Use Chrome Browser)");
      return;
    }

    let recognition = null;

    if (recordBtnState === RECORD_STATE_TYPE.QUESTIONING || recordBtnState === RECORD_STATE_TYPE.ANSWERING) {
      recognition = new SpeechRecognition();

      recognition.lang = "ko";
      recognition.continuous = true;
      recognition.interimResults = true;

      recognition.onstart = () => {
        console.log(`Voice recognition started. Record State ${recordBtnState}`);
      };

      recognition.onresult = (event) => {
        const transcript = [...event.results].reduce(
          (acc, result) => acc + result[0].transcript,
          ""
        );

        switch (recordBtnState) {
          case RECORD_STATE_TYPE.QUESTIONING:
            setQuestion(question.concat(transcript));
            break;
          case RECORD_STATE_TYPE.ANSWERING:
            setAnswer(answer.concat(transcript));
            break;
          default:
            setQuestion(question.concat(transcript));
        }
      };

      recognition.start();
    } else {
      console.log(`else Record State ${recordBtnState}`);
    }

    return () => recognition && recognition.stop();
  }, [answer, question, recordBtnState]);

  return (
    <div>
      <button id="button" onClick={handleClickRecord}>
        {BUTTON_NAME[recordBtnState]}
      </button>
      {/* <button id="button" onClick={onClickGoogleButton}>
        {record ? "êµ¬ê¸€ ìŒì„±ì¸ì‹ ì¢…ë£Œ" : "êµ¬ê¸€ ìŒì„±ì¸ì‹ ì‹œì‘"}
      </button> */}

      <h1>ì§ˆë¬¸ : {question.join(" ")}</h1>
      <h2>ë‹µë³€ : {answer.join(" ")}</h2>
    </div>
  );
}
